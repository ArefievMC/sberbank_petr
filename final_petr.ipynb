{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "573bd3062fb1429cae88eb3b1cf54f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38a2fe987e9d48a6bf828032090aa845",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ab362eb89cd43eebe4994bb25070b5a",
              "IPY_MODEL_623dff57eaa9421fb269eb5d391b0df3"
            ]
          }
        },
        "38a2fe987e9d48a6bf828032090aa845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ab362eb89cd43eebe4994bb25070b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56c6c89882fb4adeb972301b106fc566",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6196,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6196,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dcd966201fb434ca2b259ad65313e2c"
          }
        },
        "623dff57eaa9421fb269eb5d391b0df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_571bc3764979441abce3c3426ee379ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6196/6196 [03:50&lt;00:00, 26.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_387d6f5817f44762aa0f78bde87a0166"
          }
        },
        "56c6c89882fb4adeb972301b106fc566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dcd966201fb434ca2b259ad65313e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "571bc3764979441abce3c3426ee379ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "387d6f5817f44762aa0f78bde87a0166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCY4aFxLhjZG"
      },
      "source": [
        "# !pip install -U git+https://github.com/albumentations-team/albumentations\n",
        "# import os\n",
        "# os.system(' cp \"drive/My Drive/train.zip\" \"train.zip\" ')\n",
        "# os.system(' unzip train.zip' )"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyBpW92f6Ara",
        "scrolled": true
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from os.path import join\n",
        "from collections import Counter\n",
        "\n",
        "import editdistance\n",
        "\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, Dropout, AveragePooling2D, Input, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "import imutils\n",
        "from keras.optimizers import *\n",
        "\n",
        "import albumentations as A\n",
        "import pickle\n",
        "import gc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2OwuC9NnOw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84e3ad3-8073-4fab-83b6-643ee49bdb0d"
      },
      "source": [
        "print('TensorFlow version:', tf.__version__)\n",
        "print('Keras version:', keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "Keras version: 2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIzLKaySn0U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaea869d-a03a-42c0-9b48-e3cd41764e3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_m5PGvYnOw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedd829e-38f1-4325-d11c-cff4f5667040"
      },
      "source": [
        "#В этой папке лежат txt файлы перевода\n",
        "trans_dir = os.path.join('train', 'words')\n",
        "#В этой папке лежат  jpg файлы изображений\n",
        "image_dir = os.path.join('train', 'images')\n",
        "\n",
        "print(len(os.listdir(trans_dir)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKRqh5haZ5_o"
      },
      "source": [
        "max_len = 60"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUU-4MXEnOxN"
      },
      "source": [
        "def text_to_labels(text, letters):\n",
        "    return list(map(lambda x: letters.index(x), text))\n",
        "\n",
        "english_letters = ''\n",
        "\n",
        "def read_target(trans_dir, english_drop = True):\n",
        "    target_folders = [os.path.join(trans_dir, p) for i, p in enumerate( sorted(os.listdir(trans_dir)))]\n",
        "    len_target = []\n",
        "    real_targets = []\n",
        "    for file in target_folders:\n",
        "        with open(file, 'r',  encoding='utf8') as file:\n",
        "            data = file.read()\n",
        "                       \n",
        "            if english_drop:\n",
        "              data = data.replace('u', '')\n",
        "              data = data.replace('–', ' ')\n",
        "              data = data.replace('l', '|')\n",
        "              data = data.replace('a', 'а').replace('b', 'б').replace('k', '')\n",
        "              data = data.replace('ǂ', '')\n",
        "            data = ' '.join(data.split())\n",
        "            data = data.lstrip().rstrip()\n",
        "        if len(set(data) & set(english_letters)) != 0 and english_drop:\n",
        "          real_targets += ['12345']\n",
        "          len_target += [5]\n",
        "        else:\n",
        "          real_targets += [data]\n",
        "          len_target += [len(data)]        \n",
        "        \n",
        "    max_label_len = max(len_target)\n",
        "    letters = sorted(list(set(''.join(real_targets))))\n",
        "\n",
        "    convert_targets = [text_to_labels(t, letters) for t in real_targets]\n",
        "    \n",
        "    targets = pad_sequences(convert_targets, \n",
        "                             maxlen=max_label_len, \n",
        "                             padding='post',\n",
        "                             value=len(letters))\n",
        "    return np.array(targets), real_targets, letters, np.array(len_target)\n",
        "\n",
        "# os.system(' cp \"drive/My Drive/checker.py\" \"checker.py\" ')\n",
        "# !python checker.py 'train/words'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaVOusFUnOxP"
      },
      "source": [
        "targets, real_targets, letters, len_targets = read_target(trans_dir)\n",
        "targets_f, real_targets_f, letters_f, len_targets_f = read_target(trans_dir, False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll9vglD_5qz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634afa75-0834-489e-f334-68192d917e1d"
      },
      "source": [
        "print(letters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', ')', '+', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '[', ']', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'm', 'n', 'o', 'p', 'r', 's', 't', '|', '×', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'і', 'ѣ', '…', '⊕', '⊗']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LVEjh0icLRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e80cd3-ed85-4522-aca0-3771b0bf924a"
      },
      "source": [
        "def block(x, f):\n",
        "    def b(x):\n",
        "        conv_1 = Conv2D(f, (3, 3),  padding='same')(x)\n",
        "        bn = BatchNormalization()(conv_1)\n",
        "        rel = ReLU()(bn)\n",
        "        return rel\n",
        "    return b\n",
        "\n",
        "def block_0(x, f):\n",
        "    def b(x):\n",
        "        conv_1 = Conv2D(f, (3, 3), activation='relu',  padding='same')(x)\n",
        "        bn = BatchNormalization()(conv_1)\n",
        "        return bn\n",
        "    return b\n",
        "    \n",
        "max_label_len = max(len_targets)\n",
        "max_label_len = 60\n",
        "\n",
        "def crnn(w_good = 64, h_good = 64 * 8):\n",
        "\n",
        "    inputs = Input(shape=(w_good, h_good, 1))\n",
        "\n",
        "    x = block(inputs, 64)(inputs)\n",
        "    x = block(x, 64)(x)\n",
        "    x = block(x, 64)(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2), strides=2)(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "\n",
        "    x = block(x, 128)(x)\n",
        "    x = block(x, 128)(x)\n",
        "    x = block(x, 128)(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "\n",
        "    x = block(x, 256)(x)\n",
        "    x = block(x, 256)(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 1))(x)\n",
        "    x = Dropout(rate=0.3)(x)\n",
        "\n",
        "    x = block_0(x, 512)(x)\n",
        "    x = block_0(x, 512)(x)\n",
        "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 1))(x)\n",
        "    x = Dropout(rate=0.3)(x)\n",
        "\n",
        "    x = block_0(x, 768)(x)\n",
        "    x = block_0(x, 768)(x)\n",
        "    ap = AveragePooling2D(pool_size=(4, 1), padding='same' )(x)\n",
        "\n",
        "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(ap)\n",
        "\n",
        "    blstm_1 = Bidirectional(LSTM(160, return_sequences=True, dropout=0.5))(squeezed)\n",
        "    blstm_2 = Bidirectional(LSTM(160, return_sequences=True, dropout=0.5))(blstm_1)\n",
        "    blstm_3 = Bidirectional(LSTM(196, return_sequences=True, dropout=0.5))(blstm_2)\n",
        "\n",
        "    outputs = Dense(len(letters) + 1, activation='softmax')(blstm_3)\n",
        "    act_model = Model(inputs=[inputs], outputs=outputs)\n",
        "\n",
        "    the_labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "    def ctc_lambda_func(args):\n",
        "        y_pred, labels, input_length, label_length = args\n",
        "\n",
        "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, the_labels, input_length, label_length])\n",
        "\n",
        "    model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "    return model, act_model\n",
        "\n",
        "\n",
        "model, act_model = crnn()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64, 512, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 512, 64)  640         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 512, 64)  256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 64, 512, 64)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 512, 64)  36928       re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 512, 64)  256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 64, 512, 64)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 512, 64)  36928       re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 512, 64)  256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 64, 512, 64)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 256, 64)  0           re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 256, 64)  0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 256, 128) 73856       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 256, 128) 512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 32, 256, 128) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 256, 128) 147584      re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 256, 128) 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 32, 256, 128) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 256, 128) 147584      re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 256, 128) 512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 32, 256, 128) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 128, 128) 0           re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 128, 128) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 128, 256) 295168      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 128, 256) 1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 16, 128, 256) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 128, 256) 590080      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 128, 256) 1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 16, 128, 256) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 127, 256)  0           re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 127, 256)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 127, 512)  1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 127, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 127, 512)  2359808     batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 127, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 126, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 4, 126, 512)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 126, 768)  3539712     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 126, 768)  3072        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 4, 126, 768)  5309184     batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 4, 126, 768)  3072        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 126, 768)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 126, 768)     0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 126, 320)     1189120     lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 126, 320)     615680      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 126, 392)     810656      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 126, 70)      27510       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         [(None, 60)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           dense[0][0]                      \n",
            "                                                                 the_labels[0][0]                 \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 16,375,190\n",
            "Trainable params: 16,367,894\n",
            "Non-trainable params: 7,296\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbohczZBMzfb",
        "outputId": "491d278d-d4fc-44d9-ad81-939b33b13bd1"
      },
      "source": [
        "output_feats = model.layers[-5].output_shape[1]\n",
        "output_feats"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yg_N3sptanb"
      },
      "source": [
        "import random \n",
        "\n",
        "\n",
        "def generate_batches(ind, targets, len_targets, batch_size = 8, root_images=None, root_words=None,\n",
        "                     w_good = 128, h_good = 1024, aug = True):\n",
        "    counter = 0\n",
        "\n",
        "    ind = np.sort(ind)\n",
        "\n",
        "    name_files_words  = [os.path.join(root_words, p) for i, p in enumerate( sorted(os.listdir(root_words)))]\n",
        "    name_files_images = []\n",
        "    for i in ind:\n",
        "      name_files_images += [name_files_words[i].replace(root_words, root_images).replace('txt', 'jpg')]\n",
        "    \n",
        "    k = 0\n",
        "    while True:\n",
        "      random.seed(k)\n",
        "      new_ind = np.arange(len(ind))\n",
        "      random.shuffle(new_ind)\n",
        "      targets_shuffle = targets[ind[new_ind]]\n",
        "      len_targets_shuffle = len_targets[ind[new_ind]]\n",
        "      name_files_images_shuffle = [name_files_images[x] for x in new_ind]\n",
        "      k += 1\n",
        "\n",
        "      num_iter = len(name_files_images) // batch_size + int((len(name_files_images) % batch_size) > 0)\n",
        "      for counter in range(0, num_iter):\n",
        "          inames = name_files_images_shuffle[counter * batch_size : (counter + 1) * batch_size]\n",
        "          list_img = []\n",
        "          dim_img = []\n",
        "          for path in inames:\n",
        "              img = image_array_new[dict_name[path]]\n",
        "              if aug:\n",
        "                p = 0.35\n",
        "                t =  A.Compose([\n",
        "                    A.Rotate([-3, 3], p = p, border_mode=1),\n",
        "                ])\n",
        "\n",
        "                aug_num = random.choice(np.arange(1, 15))\n",
        "                if aug_num in [1,2,3,4,5,6]:\n",
        "                    ind_num = random.choice(np.arange(30))\n",
        "                    img = image_array_new_aug0[dict_name[path]][ind_num]\n",
        "                elif aug_num in [7,8,9]:\n",
        "                    ind_num = random.choice(np.arange(15))\n",
        "                    img = image_array_new_aug1[dict_name[path]][ind_num]\n",
        "                elif aug_num in [10,11]:\n",
        "                    ind_num = random.choice(np.arange(10))\n",
        "                    img = image_array_new_aug2[dict_name[path]][ind_num]\n",
        "                elif aug_num in [12]:\n",
        "                    ind_num = random.choice(np.arange(5))\n",
        "                    img = image_array_new_aug3[dict_name[path]][ind_num]\n",
        "                else:\n",
        "                    ind_num = random.choice(np.arange(10))\n",
        "                    img = image_array_new_aug4[dict_name[path]][ind_num]                 \n",
        "                img = t( image = img)['image']\n",
        "\n",
        "              else:\n",
        "                1\n",
        "\n",
        "              list_img += [img]\n",
        "              \n",
        "\n",
        "          list_img = normalization(list_img)\n",
        "          target = targets_shuffle[counter * batch_size : (counter + 1) * batch_size] \n",
        "          len_input = np.array(([output_feats] * len(target)))\n",
        "          len_target = len_targets_shuffle[counter * batch_size : (counter + 1) * batch_size]\n",
        "          dim_img = np.array(dim_img)\n",
        "\n",
        "          yield ( [list_img,  target, len_input, len_target], np.zeros(len(target)) )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y_ysZEps9pw"
      },
      "source": [
        "def normalization(imgs):\n",
        "    \"\"\"Normalize list of images\"\"\"\n",
        "\n",
        "    imgs = np.asarray(imgs).astype(np.float32)\n",
        "    # print(imgs.shape)\n",
        "    _, h, w, _ = imgs.shape\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        m, s = cv2.meanStdDev(imgs[i])\n",
        "        imgs[i] = imgs[i] - m[0][0]\n",
        "        imgs[i] = imgs[i] / s[0][0] if s[0][0] > 0 else imgs[i]\n",
        "\n",
        "    return imgs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ES4_Zjeljb"
      },
      "source": [
        "def process_image(img, w_good=128, h_good=1024, fill = 190):\n",
        "    w, h = img.shape\n",
        "\n",
        "    if w < 200 and h / w < 2.5:\n",
        "      new_w = int(w_good * 0.8)\n",
        "    else:\n",
        "      new_w = w_good\n",
        "    new_h = int(h * (new_w / w))\n",
        "    if new_h > img.shape[1] :\n",
        "        img = cv2.resize(img, (new_h, new_w), interpolation = cv2.INTER_CUBIC )\n",
        "    else:\n",
        "        img = cv2.resize(img, (new_h, new_w), interpolation = cv2.INTER_AREA )\n",
        "    # img = (img - np.mean(img)) / ( np.std(img) + 1e-8 )\n",
        "\n",
        "    w, h = img.shape\n",
        "\n",
        "    img = img.astype('float32')\n",
        "\n",
        "    if w < w_good:\n",
        "        add_zeros = np.full((w_good - w, h), fill)\n",
        "        img = np.concatenate((img, add_zeros))\n",
        "        w, h = img.shape\n",
        "\n",
        "    if h < h_good:\n",
        "        add_zeros = np.full((w, h_good - h), fill)\n",
        "        img = np.concatenate((img, add_zeros), axis=1)\n",
        "        w, h = img.shape\n",
        "\n",
        "    if h > h_good or w > w_good:\n",
        "        dim = (h_good, w_good)\n",
        "        if h_good > img.shape[1] :\n",
        "          img = cv2.resize(img, dim, interpolation = cv2.INTER_CUBIC )\n",
        "        else:\n",
        "          img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA )\n",
        "\n",
        "    # print(img)\n",
        "    img = img.astype(np.float32)\n",
        "\n",
        "    img = img.reshape((img.shape[0], img.shape[1], 1))\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGNVWkSUSwZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "573bd3062fb1429cae88eb3b1cf54f1b",
            "38a2fe987e9d48a6bf828032090aa845",
            "4ab362eb89cd43eebe4994bb25070b5a",
            "623dff57eaa9421fb269eb5d391b0df3",
            "56c6c89882fb4adeb972301b106fc566",
            "7dcd966201fb434ca2b259ad65313e2c",
            "571bc3764979441abce3c3426ee379ae",
            "387d6f5817f44762aa0f78bde87a0166"
          ]
        },
        "outputId": "deede26c-d315-4d7a-90e3-effbdfa0710c"
      },
      "source": [
        "w_good = 64\n",
        "h_good = 64 * 8\n",
        "\n",
        "\n",
        "name_files_words  = [os.path.join(trans_dir, p) for i, p in enumerate( sorted(os.listdir(trans_dir)))]\n",
        "name_files_images = [p.replace(trans_dir, image_dir).replace('txt', 'jpg') for p in  name_files_words]\n",
        "def make_dict_photo():\n",
        "  image_array = []\n",
        "  img_sizes = []\n",
        "  i = 0\n",
        "  for p in tqdm.tqdm_notebook(name_files_images):\n",
        "    img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
        "    med = np.clip(np.median(img[img <= 250]), 180, 200)\n",
        "    img[img > 250] = med\n",
        "\n",
        "    if img.shape[0] > 1000:\n",
        "      if p == 'train/images/221_10_22.jpg' or p == 'train/images/221_10_23.jpg':\n",
        "        img = imutils.rotate_bound(img, 90)\n",
        "      else:\n",
        "        img = imutils.rotate_bound(img, -90)\n",
        "    elif img.shape[0] > img.shape[1] and img.shape[0] >= 200 and img.shape[0] / img.shape[1] > 2:\n",
        "      img = imutils.rotate_bound(img, -90)\n",
        "\n",
        "\n",
        "    image_array += [ process_image(img, w_good, h_good, med) ]\n",
        "  image_array_new = np.array(image_array).astype('uint8')\n",
        "  return image_array_new\n",
        "\n",
        "image_array_new = make_dict_photo()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573bd3062fb1429cae88eb3b1cf54f1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6196.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AVhZdsek3GV"
      },
      "source": [
        "Делаем аугментации, затем их надо сохранить в pickle чтобы каждый раз не повторять этот процесс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnvZZpgZkIVl"
      },
      "source": [
        "# os.system(' cp -avr \"drive/My Drive/aug.py\" \"aug.py\" ')\n",
        "# import aug as augment\n",
        "\n",
        "# def make_aug_photo(image_array_new, k_aug, numaug, dis = True):\n",
        "#     image_array_new_aug = np.zeros([image_array_new.shape[0], numaug] +list(image_array_new.shape[1:]) , dtype = 'uint8')\n",
        "#     for i in tqdm.tqdm_notebook(range(image_array_new.shape[0])):\n",
        "#         img = np.squeeze(image_array_new[i])\n",
        "#         list_img = np.zeros([ numaug] + list(image_array_new.shape[1:]) , dtype = 'uint8')\n",
        "#         for k in range(numaug):\n",
        "#           if dis:\n",
        "#             list_img[k, :, :, 0] = augment.distort(img, k_aug)\n",
        "#           else:\n",
        "#             list_img[k, :, :, 0] = augment.stretch(img, k_aug)\n",
        "\n",
        "#         image_array_new_aug[i] = list_img\n",
        "\n",
        "#     return image_array_new_aug\n",
        "\n",
        "# image_array_new_aug0 = make_aug_photo(image_array_new, 3, 30)\n",
        "# image_array_new_aug1 = make_aug_photo(image_array_new, 4, 15)\n",
        "# image_array_new_aug2 = make_aug_photo(image_array_new, 5, 10)\n",
        "# image_array_new_aug3 = make_aug_photo(image_array_new, 6, 5)\n",
        "# image_array_new_aug4 = make_aug_photo(image_array_new, 3, 10, False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XglknGFmasi2"
      },
      "source": [
        "with open('drive/My Drive/distort_3_0.pickle', 'rb') as f:\n",
        "    image_array_new_aug0 = pickle.load(f)\n",
        "\n",
        "with open('drive/My Drive/distort4_0.pickle', 'rb') as f:\n",
        "    image_array_new_aug1 = pickle.load(f)\n",
        "\n",
        "with open('drive/My Drive/distort5_0.pickle', 'rb') as f:\n",
        "    image_array_new_aug2 = pickle.load(f)\n",
        "\n",
        "with open('drive/My Drive/distort6_0.pickle', 'rb') as f:\n",
        "    image_array_new_aug3 = pickle.load(f)\n",
        "\n",
        "with open('drive/My Drive/stretch3_0.pickle', 'rb') as f:\n",
        "    image_array_new_aug4 = pickle.load(f)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEJRwtzJ4kr"
      },
      "source": [
        "gc.collect()\n",
        "dict_name = {p:i for i,p in enumerate(name_files_images)}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3edvyAVA-gT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4j24y0fwl7-"
      },
      "source": [
        "names_pref = [n.split('/')[-1].split('_')[0] for n in name_files_words]\n",
        "\n",
        "bad_ind = ['368_3_0', '460_9_9' ,'337_46_6']\n",
        "bad_ind = [i for i, x in enumerate(name_files_words) if x.split('/')[-1].split('.')[0] in bad_ind]\n",
        "\n",
        "\n",
        "gp = GroupKFold(5)\n",
        "\n",
        "split_list = []\n",
        "for train_ind, val_ind in gp.split(names_pref,names_pref, names_pref):\n",
        "    new_train_ind = []\n",
        "    for ind in np.arange(len(names_pref)):\n",
        "    # for ind in train_ind:\n",
        "      if real_targets[ind] != '12345' :\n",
        "        if ind not in bad_ind :\n",
        "            if len_targets_f[ind] < 63:\n",
        "              new_train_ind += [ind]\n",
        "    new_val_ind = []\n",
        "    for ind in val_ind:\n",
        "      if real_targets[ind] != '12345' :\n",
        "        if ind not in bad_ind:\n",
        "          new_val_ind += [ind]\n",
        "    split_list += [(new_train_ind, new_val_ind, val_ind)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfkjXoSgmenO"
      },
      "source": [
        "class Show_lr(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.lr\n",
        "        # If you want to apply decay.\n",
        "        decay = self.model.optimizer.decay\n",
        "        \n",
        "        iterations = self.model.optimizer.iterations\n",
        "        lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
        "        # print(epoch, lr, decay, iterations, K.cast(iterations, K.dtype(decay)))\n",
        "        print(K.eval(lr_with_decay))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1kYUxGns5J4"
      },
      "source": [
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data, steps):\n",
        "        \"\"\"\n",
        "        valid_data is a TFRecordDataset with batches of 100 elements per batch, shuffled and repeated infinitely. \n",
        "        steps defines the amount of batches per epoch\n",
        "        \"\"\"\n",
        "        super(Metrics, self).__init__()\n",
        "        self.valid_data = valid_data\n",
        "        self.steps = steps\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.cer = []\n",
        "        self.wer = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        if epoch % 5 != 0:\n",
        "          return\n",
        "\n",
        "        labels = []\n",
        "        prediction = []\n",
        "        for i in range(self.steps) :\n",
        "            data = next(self.valid_data)\n",
        "            # print(data[0][0].shape)\n",
        "            prediction += [act_model.predict([data[0][0]])]\n",
        "            labels += [data[0][1]]\n",
        "        prediction =  np.concatenate(prediction)\n",
        "        labels =  np.concatenate(labels)\n",
        "\n",
        "        decoded = K.ctc_decode(prediction, \n",
        "                              input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                              greedy=True)[0][0]\n",
        "        out = K.get_value(decoded)\n",
        "\n",
        "        numCharErr = 0\n",
        "        numCharTotal = 0\n",
        "        numStringOK = 0\n",
        "        numStringTotal = 0\n",
        "\n",
        "        word_eds, word_true_lens = [], []\n",
        "\n",
        "        real_answer = []\n",
        "        for x in labels:\n",
        "            real_answer += [ ''.join([letters[i] for i in x if i != len(letters) ])]\n",
        "        for i in range(len(out)):\n",
        "            pred = ''\n",
        "            for p in out[i]:\n",
        "                if int(p) != -1:\n",
        "                    pred+=letters[int(p)]\n",
        "\n",
        "                    \n",
        "            true = real_answer[i]\n",
        "            \n",
        "            numStringOK += 1 if true == pred else 0\n",
        "            numStringTotal += 1\n",
        "            dist = editdistance.eval(pred, true)\n",
        "            numCharErr += dist\n",
        "            numCharTotal += len(true)\n",
        "            \n",
        "            pred_words = pred.split()\n",
        "            true_words = true.split()\n",
        "            word_eds.append(editdistance.eval(pred_words, true_words))\n",
        "            word_true_lens.append(len(true_words))\n",
        "\n",
        "        charErrorRate = numCharErr / numCharTotal\n",
        "        wordErrorRate = sum(word_eds) / sum(word_true_lens) \n",
        "        stringAccuracy = numStringOK / numStringTotal\n",
        "        print('Character error rate: %f%%. Word error rate: %f%%. String accuracy: %f%%.' % \\\n",
        "              (charErrorRate*100.0,wordErrorRate*100.0, stringAccuracy*100.0))\n",
        "\n",
        "        print('-------------------------------')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyvL9I-5zXlY"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "   lr = 0.001\n",
        "   if epoch < 100:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr * 0.965 ** ((epoch - 100) + 1) \n",
        "callback_lr_my = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ru4RbCGzY9S"
      },
      "source": [
        "# tf.keras.backend.clear_session()\n",
        "# del model\n",
        "# del act_model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQleTQKTcLrL"
      },
      "source": [
        "num_e = 3\n",
        "\n",
        "for train_index, test_index, real_test_index in split_list[3:]:\n",
        "    num_e += 1\n",
        "    print(len(train_index), len(test_index), len(real_test_index) )\n",
        "    batch_size = 32\n",
        "    epochs = 300\n",
        "\n",
        "    gen_tr = generate_batches(train_index, targets, len_targets, batch_size, image_dir, trans_dir,w_good, h_good)\n",
        "    gen_val = generate_batches(test_index, targets, len_targets, batch_size, image_dir, trans_dir, w_good, h_good, False)\n",
        "    # hui\n",
        "    \n",
        "    os.makedirs('drive/My Drive/checkpoint{}'.format(num_e), exist_ok=True)\n",
        "\n",
        "    filepath=\"drive/My Drive/checkpoint{}\".format(num_e) + \"/model_{epoch}.hdf5\"\n",
        "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=500)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, verbose = 1,\n",
        "                                  patience=5, min_lr=0.00001)\n",
        "    print_lr = Show_lr() \n",
        "    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    model, act_model = crnn(w_good, h_good)\n",
        "\n",
        "\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = Adam(0.001), metrics=['accuracy'])\n",
        "\n",
        "    steps_per_epoch =  len(train_index) // batch_size + int((len(train_index) % batch_size) > 0)  \n",
        "    validation_steps = len(test_index) // batch_size + int((len(test_index) % batch_size) > 0)\n",
        "\n",
        "\n",
        "    # gen_val_m = generate_batches(test_index, targets, len_targets, batch_size, image_dir, trans_dir, w_good, h_good, False)\n",
        "    # validation_steps_m = len(test_index) // batch_size + int((len(test_index) % batch_size) > 0)\n",
        "    # metric = Metrics(gen_val_m, validation_steps_m)\n",
        "\n",
        "    # callbacks_list = [checkpoint, es, print_lr, callback_lr_my, metric]\n",
        "\n",
        "    # history = model.fit(gen_tr, steps_per_epoch = steps_per_epoch, epochs=epochs, verbose=1,\n",
        "    #                 callbacks=callbacks_list,  \n",
        "    #                 validation_data = gen_val, validation_steps = validation_steps)\n",
        "  \n",
        "\n",
        "    callbacks_list = [print_lr, callback_lr_my]\n",
        "    history = model.fit(gen_tr, steps_per_epoch = steps_per_epoch, epochs=epochs, verbose=1,  callbacks=callbacks_list)\n",
        "    \n",
        "    filepath = os.path.join('drive/My Drive/checkpoint{}'.format(num_e), 'model45.hdf5')\n",
        "    model.save_weights(filepath)\n",
        "    \n",
        "    hi\n",
        "    tf.keras.backend.clear_session()\n",
        "    del model\n",
        "    del act_model"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}